{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Wider_Face.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOp4Y96kT3u/Jar4yOzPbGY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pankajd007/WIDER-Face-Detection-using-Tensorflow/blob/main/Wider_Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSVAWWwmEcZU"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "In this notebook, we implement [The TensorFlow 2 Object Detection Library](https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html) for training on our own dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J-y29IHEhC3"
      },
      "source": [
        "\n",
        "We will take the following steps to implement EfficientDet D0 on our custom data:\n",
        "* Install TensorFlow2 Object Detection Dependencies\n",
        "* Download Custom TensorFlow2 Object Detection Dataset\n",
        "* Write Custom TensorFlow2 Object Detection Training Configuation\n",
        "* Train Custom TensorFlow2 Object Detection Model\n",
        "* Export Custom TensorFlow2 Object Detection Weights\n",
        "* Use Trained TensorFlow2 Object Detection For Inference on Test Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9001ilSeEzJs"
      },
      "source": [
        "# Install TensorFlow2 Object Detection Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKXsIBnTkzBb",
        "outputId": "82c39586-21fd-4d9d-f268-aa2907ff6497"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "# Clear any logs from previous runs\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2600, done.\u001b[K\n",
            "remote: Counting objects: 100% (2600/2600), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2152/2152), done.\u001b[K\n",
            "remote: Total 2600 (delta 645), reused 1267 (delta 415), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2600/2600), 32.55 MiB | 22.54 MiB/s, done.\n",
            "Resolving deltas: 100% (645/645), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhghwCcLk5ww",
        "outputId": "11b4ca21-3fb6-4814-e93a-02a06d56765b"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n",
            "Collecting apache-beam\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/e7/d6e5a3786d9a037a38af966bf154bcd6cb3cbea2edffda00cf6c417cc9a2/apache_beam-2.28.0-cp37-cp37m-manylinux2010_x86_64.whl (9.0MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.22)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official\n",
            "  Downloading https://files.pythonhosted.org/packages/57/4a/23a08f8fd2747867ee223612e219eeb0d11c36116601d99b55ef3c72e707/tf_models_official-2.4.0-py2.py3-none-any.whl (1.1MB)\n",
            "Requirement already satisfied: numpy<1.20.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Collecting pyarrow<3.0.0,>=0.15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/8d/c002e27767595f22aa09ed0d364327922f673d12b36526c967a2bf6b2ed7/pyarrow-2.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.7MB)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/26/cc1acc339eb1b8423c32b0a1dca524214012e577c22ce8fdd58d5213f9b4/fastavro-1.4.0-cp37-cp37m-manylinux2014_x86_64.whl (2.2MB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.3)\n",
            "Collecting mock<3.0.0,>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (54.2.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.4.1)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/6d/92f377bece9b0ec9c893081dbe073a65b38d7ac12ef572b8f70554d08760/opencv_python_headless-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (37.6MB)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
            "Collecting sentencepiece\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Collecting pbr>=0.11\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.29.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.3.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.28.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, future, dill, py-cpuinfo, seqeval\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1643821 sha256=a74a65465c96c43d101bebf84e1f621b113b33b5a28c5ea95a0b1c67578bbbd1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3azmj9es/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=15d2d5d2876c4691dee907927028bda918de05bc1f04133c01b283c7c47c809e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n",
            "  Building wheel for future (setup.py): started\n",
            "  Building wheel for future (setup.py): finished with status 'done'\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=28529de5db06b8fd51919b67f91aa546fc97982642925ad27c3ed5df7e156273\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78532 sha256=87110b27e125e8641e4f6482a065dc967f8fd22a1687c02dff7a2ec1bbabfc6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=0a53bd468f68f0d87a5a2893dc7bc37ec2657b39a26c9a9f8e997eac0d356878\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=811b10fe4c3e42358a2a6a8161c15efe22f71d7b5e82f4b96acb7103c2cdaca1\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built object-detection avro-python3 future dill py-cpuinfo seqeval\n",
            "Installing collected packages: avro-python3, pyarrow, requests, future, hdfs, fastavro, dill, pbr, mock, apache-beam, tf-slim, lvis, tensorflow-model-optimization, pyyaml, tensorflow-addons, py-cpuinfo, seqeval, opencv-python-headless, dataclasses, sentencepiece, tf-models-official, object-detection\n",
            "  Found existing installation: pyarrow 3.0.0\n",
            "    Uninstalling pyarrow-3.0.0:\n",
            "      Successfully uninstalled pyarrow-3.0.0\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed apache-beam-2.28.0 avro-python3-1.10.2 dataclasses-0.6 dill-0.3.1.1 fastavro-1.4.0 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 mock-2.0.0 object-detection-0.1 opencv-python-headless-4.5.1.48 pbr-5.5.1 py-cpuinfo-8.0.0 pyarrow-2.0.0 pyyaml-5.4.1 requests-2.25.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorflow-addons-0.12.1 tensorflow-model-optimization-0.5.0 tf-models-official-2.4.0 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\n",
            "ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\n",
            "ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "ERROR: apache-beam 2.28.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zddy1FV9k_MX"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIHaCqz3lGfg",
        "outputId": "50e8a511-b858-4f10-e306-450dee8c0bee"
      },
      "source": [
        "#run model builder test\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-20 12:18:30.819610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Running tests under Python 3.7.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "2021-04-20 12:18:33.738381: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-20 12:18:33.740042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-20 12:18:33.810730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-20 12:18:33.811619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-04-20 12:18:33.811669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-20 12:18:33.964187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-20 12:18:33.964379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-20 12:18:34.148346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-20 12:18:34.190182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-20 12:18:34.451571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-20 12:18:34.473198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-20 12:18:34.478444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-20 12:18:34.478601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-20 12:18:34.479485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-20 12:18:34.483764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-20 12:18:34.484283: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-20 12:18:34.484454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-20 12:18:34.485218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-04-20 12:18:34.485257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-20 12:18:34.485330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-20 12:18:34.485405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-20 12:18:34.485452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-20 12:18:34.485500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-20 12:18:34.485539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-20 12:18:34.485584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-20 12:18:34.485629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-20 12:18:34.485757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-20 12:18:34.486582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-20 12:18:34.487288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-20 12:18:34.490613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-20 12:18:38.738938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-20 12:18:38.739010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-20 12:18:38.739032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-20 12:18:38.745915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-20 12:18:38.746742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-20 12:18:38.747491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-20 12:18:38.748158: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-20 12:18:38.748218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10637 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 5.96s\n",
            "I0420 12:18:39.418893 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 5.96s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.42s\n",
            "I0420 12:18:39.839744 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.42s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0420 12:18:39.840633 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0420 12:18:39.874193 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "I0420 12:18:39.900476 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I0420 12:18:39.927298 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.17s\n",
            "I0420 12:18:40.100644 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
            "I0420 12:18:40.273304 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.19s\n",
            "I0420 12:18:40.460972 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.19s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.18s\n",
            "I0420 12:18:40.641061 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n",
            "I0420 12:18:40.825421 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "I0420 12:18:40.874566 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0420 12:18:41.225617 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0420 12:18:41.225848 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0420 12:18:41.225972 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0420 12:18:41.232577 139941820827520 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0420 12:18:41.284566 139941820827520 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0420 12:18:41.284811 139941820827520 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0420 12:18:41.374025 139941820827520 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0420 12:18:41.374400 139941820827520 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0420 12:18:41.566890 139941820827520 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0420 12:18:41.567164 139941820827520 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0420 12:18:41.761467 139941820827520 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0420 12:18:41.761672 139941820827520 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0420 12:18:42.042010 139941820827520 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0420 12:18:42.042215 139941820827520 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0420 12:18:42.327627 139941820827520 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0420 12:18:42.327816 139941820827520 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0420 12:18:42.816097 139941820827520 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0420 12:18:42.816289 139941820827520 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0420 12:18:42.905423 139941820827520 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0420 12:18:42.951224 139941820827520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0420 12:18:43.034101 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0420 12:18:43.034272 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0420 12:18:43.034386 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0420 12:18:43.039347 139941820827520 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0420 12:18:43.058343 139941820827520 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0420 12:18:43.058503 139941820827520 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0420 12:18:43.208638 139941820827520 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0420 12:18:43.208834 139941820827520 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0420 12:18:43.486607 139941820827520 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0420 12:18:43.486879 139941820827520 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0420 12:18:43.760392 139941820827520 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0420 12:18:43.760592 139941820827520 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0420 12:18:44.123187 139941820827520 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0420 12:18:44.123428 139941820827520 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0420 12:18:44.506350 139941820827520 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0420 12:18:44.506567 139941820827520 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0420 12:18:44.968986 139941820827520 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0420 12:18:44.969194 139941820827520 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0420 12:18:45.151568 139941820827520 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0420 12:18:45.185843 139941820827520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0420 12:18:45.279987 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0420 12:18:45.280162 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0420 12:18:45.280273 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0420 12:18:45.285081 139941820827520 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0420 12:18:45.303683 139941820827520 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0420 12:18:45.303819 139941820827520 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0420 12:18:45.452457 139941820827520 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0420 12:18:45.452630 139941820827520 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0420 12:18:45.724460 139941820827520 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0420 12:18:45.724666 139941820827520 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0420 12:18:46.010605 139941820827520 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0420 12:18:46.010788 139941820827520 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0420 12:18:46.549922 139941820827520 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0420 12:18:46.550126 139941820827520 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0420 12:18:46.919492 139941820827520 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0420 12:18:46.919707 139941820827520 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0420 12:18:47.387313 139941820827520 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0420 12:18:47.387528 139941820827520 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0420 12:18:47.577891 139941820827520 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0420 12:18:47.613935 139941820827520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0420 12:18:47.703943 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0420 12:18:47.704183 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0420 12:18:47.704292 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0420 12:18:47.709753 139941820827520 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0420 12:18:47.728673 139941820827520 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0420 12:18:47.728811 139941820827520 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0420 12:18:47.868615 139941820827520 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0420 12:18:47.868806 139941820827520 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0420 12:18:48.151145 139941820827520 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0420 12:18:48.151367 139941820827520 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0420 12:18:48.424869 139941820827520 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0420 12:18:48.425111 139941820827520 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0420 12:18:48.897369 139941820827520 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0420 12:18:48.897583 139941820827520 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0420 12:18:49.361219 139941820827520 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0420 12:18:49.361427 139941820827520 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0420 12:18:49.912782 139941820827520 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0420 12:18:49.913060 139941820827520 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0420 12:18:50.095895 139941820827520 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0420 12:18:50.131587 139941820827520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0420 12:18:50.234847 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0420 12:18:50.235074 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0420 12:18:50.235181 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0420 12:18:50.239709 139941820827520 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0420 12:18:50.258173 139941820827520 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0420 12:18:50.258313 139941820827520 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0420 12:18:50.397900 139941820827520 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0420 12:18:50.398067 139941820827520 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0420 12:18:50.764780 139941820827520 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0420 12:18:50.764991 139941820827520 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0420 12:18:51.357652 139941820827520 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0420 12:18:51.357978 139941820827520 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0420 12:18:51.926990 139941820827520 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0420 12:18:51.927200 139941820827520 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0420 12:18:52.523865 139941820827520 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0420 12:18:52.524079 139941820827520 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0420 12:18:53.293287 139941820827520 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0420 12:18:53.293535 139941820827520 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0420 12:18:53.476800 139941820827520 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0420 12:18:53.510637 139941820827520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0420 12:18:53.636751 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0420 12:18:53.636970 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0420 12:18:53.637089 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0420 12:18:53.641865 139941820827520 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0420 12:18:53.661191 139941820827520 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0420 12:18:53.661344 139941820827520 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0420 12:18:53.882130 139941820827520 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0420 12:18:53.882358 139941820827520 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0420 12:18:54.347154 139941820827520 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0420 12:18:54.347368 139941820827520 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0420 12:18:54.809791 139941820827520 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0420 12:18:54.810025 139941820827520 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0420 12:18:55.453247 139941820827520 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0420 12:18:55.453478 139941820827520 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0420 12:18:56.317726 139941820827520 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0420 12:18:56.317940 139941820827520 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0420 12:18:57.155057 139941820827520 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0420 12:18:57.155250 139941820827520 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0420 12:18:57.433506 139941820827520 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0420 12:18:57.474457 139941820827520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0420 12:18:57.600902 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0420 12:18:57.601131 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0420 12:18:57.601231 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0420 12:18:57.606108 139941820827520 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0420 12:18:57.624550 139941820827520 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0420 12:18:57.624679 139941820827520 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0420 12:18:57.842242 139941820827520 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0420 12:18:57.842472 139941820827520 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0420 12:18:58.392472 139941820827520 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0420 12:18:58.392678 139941820827520 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0420 12:18:58.944043 139941820827520 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0420 12:18:58.944253 139941820827520 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0420 12:18:59.691397 139941820827520 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0420 12:18:59.691620 139941820827520 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0420 12:19:00.459434 139941820827520 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0420 12:19:00.459632 139941820827520 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0420 12:19:01.726010 139941820827520 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0420 12:19:01.726221 139941820827520 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0420 12:19:02.022148 139941820827520 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0420 12:19:02.055164 139941820827520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0420 12:19:02.192027 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0420 12:19:02.192224 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0420 12:19:02.192333 139941820827520 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0420 12:19:02.197110 139941820827520 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0420 12:19:02.215017 139941820827520 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0420 12:19:02.215178 139941820827520 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0420 12:19:02.508016 139941820827520 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0420 12:19:02.508243 139941820827520 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0420 12:19:03.163142 139941820827520 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0420 12:19:03.163350 139941820827520 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0420 12:19:03.804214 139941820827520 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0420 12:19:03.804420 139941820827520 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0420 12:19:04.733510 139941820827520 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0420 12:19:04.733724 139941820827520 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0420 12:19:05.673207 139941820827520 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0420 12:19:05.673498 139941820827520 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0420 12:19:06.908614 139941820827520 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0420 12:19:06.908842 139941820827520 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0420 12:19:07.309373 139941820827520 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0420 12:19:07.342787 139941820827520 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.89s\n",
            "I0420 12:19:07.769399 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.89s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0420 12:19:07.776648 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0420 12:19:07.778603 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0420 12:19:07.779237 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0420 12:19:07.781097 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0420 12:19:07.782812 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0420 12:19:07.783421 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0420 12:19:07.784703 139941820827520 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 21 tests in 34.327s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "718oBaTUFIy-"
      },
      "source": [
        "# Prepare Tensorflow 2 Object Detection Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sWtQEy5lS_I",
        "outputId": "b7760fdd-6ee6-4813-e951-22ec26fe0cf1"
      },
      "source": [
        "!git clone https://github.com/qdraw/tensorflow-face-object-detector-tutorial"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tensorflow-face-object-detector-tutorial'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Total 61 (delta 0), reused 0 (delta 0), pack-reused 61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnzjzyPFl4A1"
      },
      "source": [
        "import requests\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\"\"\"\n",
        "Script to download\n",
        "Wider Face Training Images\n",
        "Wider Face Validation Images\n",
        "from Google Drive using Python3.6\n",
        "\n",
        "http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/\n",
        "\n",
        "Wider_face_split is included in repo\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# credits: https://stackoverflow.com/a/16664766\n",
        "# https://stackoverflow.com/questions/16664526/howto-download-file-from-drive-api-using-python-script\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    def get_confirm_token(response):\n",
        "        for key, value in response.cookies.items():\n",
        "            if key.startswith('download_warning'):\n",
        "                return value\n",
        "\n",
        "        return None\n",
        "\n",
        "    def save_response_content(response, destination):\n",
        "        CHUNK_SIZE = 32768\n",
        "\n",
        "        with open(destination, \"wb\") as f:\n",
        "            for chunk in response.iter_content(CHUNK_SIZE):\n",
        "                if chunk: # filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        "\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)\n",
        "\n",
        "\n",
        "# The script\n",
        "curr_path = os.getcwd()\n",
        "models_path = os.path.join(curr_path,\"data\")\n",
        "\n",
        "# make dir => wider_data in folder\n",
        "try:\n",
        "    os.makedirs(models_path)\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "if os.path.exists(os.path.join(models_path,\"train.zip\")) == False:\n",
        "    print(\"downloading.. train.zip -- 1.47GB\")\n",
        "    download_file_from_google_drive(\"0B6eKvaijfFUDQUUwd21EckhUbWs\", os.path.join(models_path,\"train.zip\"))\n",
        "\n",
        "if os.path.exists(os.path.join(models_path,\"val.zip\")) == False:\n",
        "    print(\"downloading.. val.zip -- 362.8MB\")\n",
        "    download_file_from_google_drive(\"0B6eKvaijfFUDd3dIRmpvSk8tLUk\", os.path.join(models_path,\"val.zip\"))\n",
        "\n",
        "print(\"files downloaded\")\n",
        "\n",
        "# unzip the files\n",
        "import zipfile\n",
        "\n",
        "if os.path.exists(os.path.join(models_path,\"WIDER_train\")) == False:\n",
        "    with zipfile.ZipFile(os.path.join(models_path,\"train.zip\"),\"r\") as zip_ref:\n",
        "        zip_ref.extractall(models_path)\n",
        "\n",
        "if os.path.exists(os.path.join(models_path,\"WIDER_val\")) == False:\n",
        "    with zipfile.ZipFile(os.path.join(models_path,\"val.zip\"),\"r\") as zip_ref:\n",
        "        zip_ref.extractall(models_path)\n",
        "\n",
        "print(\"files unziped\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkqlCxeDmKos"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfUq07W5nOIN"
      },
      "source": [
        "%cd data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tMUaYDDnR6N"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy2O_rBbvFbH"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi1pLAAEoM7j"
      },
      "source": [
        "# Upload the wider_face_split.zip from local machine\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB5AAbWEnxjY"
      },
      "source": [
        "#Extract the zip file into data folder\n",
        "if os.path.exists(os.path.join(os.getcwd(),\"wider_face_split\")) == False:\n",
        "    with zipfile.ZipFile(os.path.join(os.getcwd(),\"wider_face_split.zip\"),\"r\") as zip_ref:\n",
        "        zip_ref.extractall(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nijYC-AYOLgK"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMAUD4qvJWaD"
      },
      "source": [
        "## Converting XML files from images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_rYb0qumccU"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\"\"\"\n",
        "This script crawls over 9263 training images and 1873 items\n",
        "On my Macbook pro this takes: 4 minutes\n",
        "\n",
        "\"\"\"\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from glob import iglob # python 3.5 or newer\n",
        "from shutil import copyfile\n",
        "\n",
        "\n",
        "# The script\n",
        "curr_path = os.getcwd()\n",
        "\n",
        "import xml.etree.cElementTree as ET\n",
        "\n",
        "# settings\n",
        "cnt = 0\n",
        "hog = cv2.HOGDescriptor((80, 80), (16, 16), (8,8), (8,8), 9)\n",
        "# data = []\n",
        "# label = []\n",
        "\n",
        "\n",
        "def newXMLPASCALfile(imageheight, imagewidth, path, basename):\n",
        "    # print(filename)\n",
        "    annotation = ET.Element(\"annotation\", verified=\"yes\")\n",
        "    ET.SubElement(annotation, \"folder\").text = \"images\"\n",
        "    ET.SubElement(annotation, \"filename\").text = basename\n",
        "    ET.SubElement(annotation, \"path\").text = path\n",
        "\n",
        "    source = ET.SubElement(annotation, \"source\")\n",
        "    ET.SubElement(source, \"database\").text = \"test\"\n",
        "\n",
        "    size = ET.SubElement(annotation, \"size\")\n",
        "    ET.SubElement(size, \"width\").text = str(imagewidth)\n",
        "    ET.SubElement(size, \"height\").text = str(imageheight)\n",
        "    ET.SubElement(size, \"depth\").text = \"3\"\n",
        "\n",
        "    ET.SubElement(annotation, \"segmented\").text = \"0\"\n",
        "\n",
        "    tree = ET.ElementTree(annotation)\n",
        "    # tree.write(\"filename.xml\")\n",
        "    return tree\n",
        "\n",
        "def appendXMLPASCAL(curr_et_object,x1, y1, w, h, filename):\n",
        "    et_object = ET.SubElement(curr_et_object.getroot(), \"object\")\n",
        "    ET.SubElement(et_object, \"name\").text = \"face\"\n",
        "    ET.SubElement(et_object, \"pose\").text = \"Unspecified\"\n",
        "    ET.SubElement(et_object, \"truncated\").text = \"0\"\n",
        "    ET.SubElement(et_object, \"difficult\").text = \"0\"\n",
        "    bndbox = ET.SubElement(et_object, \"bndbox\")\n",
        "    ET.SubElement(bndbox, \"xmin\").text = str(x1)\n",
        "    ET.SubElement(bndbox, \"ymin\").text = str(y1)\n",
        "    ET.SubElement(bndbox, \"xmax\").text = str(x1+w)\n",
        "    ET.SubElement(bndbox, \"ymax\").text = str(y1+h)\n",
        "    filename = filename.strip().replace(\".jpg\",\".xml\")\n",
        "    curr_et_object.write(filename)\n",
        "    return curr_et_object\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def readAndWrite(bbx_gttxtPath):\n",
        "    cnt = 0\n",
        "    with open(bbx_gttxtPath, 'r') as f:\n",
        "        curr_img = ''\n",
        "\n",
        "        curr_filename = \"\"\n",
        "        curr_path = \"\"\n",
        "\n",
        "        curr_et_object = ET.ElementTree()\n",
        "\n",
        "\n",
        "        img = np.zeros((80, 80))\n",
        "        for line in f:\n",
        "            inp = line.split(' ')\n",
        "\n",
        "            # if line.find(\"--\") != -1:\n",
        "            #     curr_filename = line.split('--')[1]\n",
        "            #     # reset elements\n",
        "            #     # emptyEl = ET.Element(\"\")\n",
        "            #     curr_et_object = ET.ElementTree()\n",
        "\n",
        "            if len(inp)==1:\n",
        "                img_path = inp[0]\n",
        "                img_path = img_path[:-1]\n",
        "                curr_img = img_path\n",
        "                if curr_img.isdigit():\n",
        "                    continue\n",
        "                # print(Train_path+'/'+curr_img)\n",
        "                img = cv2.imread(Train_path + '/' + curr_img, 2) # POSIX only\n",
        "                # print( len(list(curr_et_object.getroot()) )  )\n",
        "                curr_filename = curr_img.split(\"/\")[1].strip()\n",
        "                curr_path = os.path.join(Train_path, os.path.dirname(curr_img))\n",
        "                curr_et_object = newXMLPASCALfile(img.shape[0],img.shape[1],curr_path, curr_filename )\n",
        "                # print( curr_et_object  )\n",
        "\n",
        "            else:\n",
        "                # print(img)\n",
        "                inp = [int(i) for i in inp[:-1]]\n",
        "                x1, y1, w, h, blur, expression, illumination, invalid, occlusion, pose = inp\n",
        "                n = max(w,h)\n",
        "                if invalid == 1 or blur > 0 or n < 50:\n",
        "                    continue\n",
        "                img2 = img[y1:y1+n, x1:x1+n]\n",
        "                img3 = cv2.resize(img2, (80, 80))\n",
        "                vec = hog.compute(img3)\n",
        "                # data.append(vec)\n",
        "                # label.append(1)\n",
        "                cnt += 1\n",
        "\n",
        "                fileNow = os.path.join(curr_path,curr_filename)\n",
        "                print(\"{}: {} {} {} {}\".format(len(vec),x1, y1, w, h) + \" \" + fileNow)\n",
        "\n",
        "                curr_et_object = appendXMLPASCAL(curr_et_object,x1, y1, w, h, fileNow )\n",
        "\n",
        "\n",
        "# ################################ TRAINING DATA 9263 ITEMS ##################################\n",
        "# # # Run Script for Training data\n",
        "Train_path = os.path.join(curr_path, \"data\", \"WIDER_train\", \"images\" )\n",
        "## comment this out\n",
        "bbx_gttxtPath = os.path.join(curr_path, \"data\", \"wider_face_split\", \"wider_face_train_bbx_gt.txt\" )\n",
        "readAndWrite(bbx_gttxtPath)\n",
        "\n",
        "\n",
        "# To folders:\n",
        "to_xml_folder = os.path.join(curr_path, \"data\", \"tf_wider_train\", \"annotations\", \"xmls\" )\n",
        "to_image_folder = os.path.join(curr_path, \"data\", \"tf_wider_train\", \"images\" )\n",
        "\n",
        "# make dir => wider_data in folder\n",
        "try:\n",
        "    os.makedirs(to_xml_folder)\n",
        "    os.makedirs(to_image_folder)\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "rootdir_glob = Train_path + '/**/*' # Note the added asterisks # This will return absolute paths\n",
        "file_list = [f for f in iglob(rootdir_glob, recursive=True) if os.path.isfile(f)]\n",
        "\n",
        "train_annotations_index = os.path.join(curr_path, \"data\", \"tf_wider_train\", \"annotations\", \"train.txt\" )\n",
        "\n",
        "with open(train_annotations_index, \"a\") as indexFile:\n",
        "    for f in file_list:\n",
        "        if \".xml\" in f:\n",
        "            print(f)\n",
        "            copyfile(f, os.path.join(to_xml_folder, os.path.basename(f) ))\n",
        "            img = f.replace(\".xml\",\".jpg\")\n",
        "            copyfile(img, os.path.join(to_image_folder, os.path.basename(img) ))\n",
        "            indexFile.write(os.path.basename(f.replace(\".xml\",\"\")) + \"\\n\")\n",
        "\n",
        "\n",
        "################################ VALIDATION DATA 1873 ITEMS ##################################\n",
        "\n",
        "# Run Script for Validation data\n",
        "Train_path = os.path.join(curr_path, \"data\", \"WIDER_val\", \"images\" )\n",
        "bbx_gttxtPath = os.path.join(curr_path, \"data\", \"wider_face_split\", \"wider_face_val_bbx_gt.txt\" )\n",
        "readAndWrite(bbx_gttxtPath)\n",
        "\n",
        "\n",
        "# To folders:\n",
        "to_xml_folder = os.path.join(curr_path, \"data\", \"tf_wider_val\", \"annotations\", \"xmls\" )\n",
        "to_image_folder = os.path.join(curr_path, \"data\", \"tf_wider_val\", \"images\" )\n",
        "\n",
        "# make dir => wider_data in folder\n",
        "try:\n",
        "    os.makedirs(to_xml_folder)\n",
        "    os.makedirs(to_image_folder)\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "\n",
        "rootdir_glob = Train_path + '/**/*' # Note the added asterisks # This will return absolute paths\n",
        "file_list = [f for f in iglob(rootdir_glob, recursive=True) if os.path.isfile(f)]\n",
        "\n",
        "train_annotations_index = os.path.join(curr_path, \"data\", \"tf_wider_val\", \"annotations\", \"val.txt\" )\n",
        "\n",
        "with open(train_annotations_index, \"a\") as indexFile:\n",
        "    for f in file_list:\n",
        "        if \".xml\" in f:\n",
        "            print(f)\n",
        "            copyfile(f, os.path.join(to_xml_folder, os.path.basename(f) ))\n",
        "            img = f.replace(\".xml\",\".jpg\")\n",
        "            copyfile(img, os.path.join(to_image_folder, os.path.basename(img) ))\n",
        "            indexFile.write(os.path.basename(f.replace(\".xml\",\"\")) + \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_fSGQzOJhlC"
      },
      "source": [
        "## Converting XML file into csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ate_ACo5mmIQ"
      },
      "source": [
        "!python /content/tensorflow-face-object-detector-tutorial/003_xml-to-csv.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y3F2W_OrfOl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS_PxL4vJmgt"
      },
      "source": [
        "# Generating tf.records files to feed into model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-AjUyZSrmU8"
      },
      "source": [
        "!python tensorflow-face-object-detector-tutorial/004_generate_tfrecord.py --images_path=data/tf_wider_train/images --csv_input=data/tf_wider_train/train.csv  --output_path=data/train.record\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abem7suqr_8E"
      },
      "source": [
        "!python /content/tensorflow-face-object-detector-tutorial/004_generate_tfrecord.py --images_path=data/tf_wider_val/images --csv_input=data/tf_wider_val/val.csv  --output_path=data/val.record\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETIQHDpFUzWT"
      },
      "source": [
        "%cat /content/models/research/deploy/pipeline_file.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoQiwDZnuj5r"
      },
      "source": [
        "test_record_fname = '/content/data/val.record'\n",
        "train_record_fname = '/content/data/train.record'\n",
        "label_map_pbtxt_fname = '/content/data/face_label.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsDPd6HJsxao"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwZ-GhXSFWIe"
      },
      "source": [
        "# Configure Custom TensorFlow2 Object Detection Training Configuration\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> In this section you can specify any model in the [TF2 OD model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) and set up your training configuration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q3qecEhszFX"
      },
      "source": [
        "##change chosen model to deploy different models available in the TF2 object detection zoo\n",
        "MODELS_CONFIG = {\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 8\n",
        "    },\n",
        "    'efficientdet-d1': {\n",
        "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "    'efficientdet-d2': {\n",
        "        'model_name': 'efficientdet_d2_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "        'efficientdet-d3': {\n",
        "        'model_name': 'efficientdet_d3_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    }\n",
        "}\n",
        "\n",
        "#in this tutorial we implement the lightweight, smallest state of the art efficientdet model\n",
        "#if you want to scale up tot larger efficientdet models you will likely need more compute!\n",
        "chosen_model = 'efficientdet-d0'\n",
        "\n",
        "num_steps = 4000 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n",
        "num_eval_steps = 50 #Perform evaluation after so many steps\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k46LhwJttpt-"
      },
      "source": [
        "#download pretrained weights\n",
        "%mkdir /content/models/research/deploy/\n",
        "%cd /content/models/research/deploy/\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1adUvYgwYUH"
      },
      "source": [
        "%cat /content/models/research/deploy/pipeline_file.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vJwS0pQtuoN"
      },
      "source": [
        "#download base training configuration file\n",
        "%cd /content/models/research/deploy\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NatlugN0VXfL"
      },
      "source": [
        "%cat /content/models/research/deploy/ssd_efficientdet_d0_512x512_coco17_tpu-8.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNEnaKfqtzqD"
      },
      "source": [
        "#prepare\n",
        "pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
        "num_classes = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiNX5wiVuKHx"
      },
      "source": [
        "#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "\n",
        "import re\n",
        "\n",
        "%cd /content/models/research/deploy\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    #fine-tune checkpoint type\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "        \n",
        "    f.write(s)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T87VqqSQuNtd"
      },
      "source": [
        "%cat /content/models/research/deploy/pipeline_file.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeuK2wkOFnSB"
      },
      "source": [
        "# Train Custom TF2 Object Detector\n",
        "\n",
        "* pipeline_file: defined above in writing custom training configuration\n",
        "* model_dir: the location tensorboard logs and saved model checkpoints will save to\n",
        "* num_train_steps: how long to train for\n",
        "* num_eval_steps: perform eval on validation set after this many steps\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXgY2COswrM2"
      },
      "source": [
        "pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n",
        "model_dir = '/content/training'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s_BOKqJxK98"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRFrU91YxOon"
      },
      "source": [
        "#run model evaluation to obtain performance metrics\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --checkpoint_dir={model_dir} \n",
        "#Not yet implemented for EfficientDet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YY6ctE_yyE3"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5eGOgklxJAQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0EhaHbq1Krc"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/eval'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHq1kJvSgjtW"
      },
      "source": [
        " \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWI31_5sGFD_"
      },
      "source": [
        "# Run Inference on Test Images with Custom TensorFlow2 Object Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYwD9rRjx37h"
      },
      "source": [
        "#export dataset above with format COCO JSON\n",
        "#or import your test images via other means. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPRES3IJhKdv"
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUOPzAxNuDz-"
      },
      "source": [
        "Test_path = os.path.join(curr_path, \"data\", \"tf_wider_val\", \"images\" )\n",
        "rootdir_glob = Test_path + '/**/*' # Note the added asterisks # This will return absolute paths\n",
        "file_list = [f for f in iglob(rootdir_glob, recursive=True) if os.path.isfile(f)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHM4M9Hhuje_"
      },
      "source": [
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm1NmVXNHpkj"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd5t_h0xHxXz"
      },
      "source": [
        "%ls '/content/training/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR7xEl0NH6DW"
      },
      "source": [
        "#recover our saved model\n",
        "pipeline_config = pipeline_file\n",
        "#generally you want to put the last ckpt from training in here\n",
        "model_dir = '/content/training/ckpt-5'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "      model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "      model=detection_model)\n",
        "ckpt.restore(os.path.join('/content/training/ckpt-5'))\n",
        "\n",
        "\n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "\n",
        "detect_fn = get_model_detection_function(detection_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aCehafWICYD"
      },
      "source": [
        "#map labels for inference decoding\n",
        "label_map_path = configs['eval_input_config'].label_map_path\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-WZBl7aIOuF"
      },
      "source": [
        "#run detector on test image\n",
        "#it takes a little longer on the first run and then runs at normal speed. \n",
        "import random\n",
        "image_path = random.choice(file_list)\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "# Things to try:\n",
        "# Flip horizontally\n",
        "# image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "# Convert image to grayscale\n",
        "# image_np = np.tile(\n",
        "#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(\n",
        "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'][0].numpy(),\n",
        "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "      detections['detection_scores'][0].numpy(),\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.5,\n",
        "      agnostic_mode=False,\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12,16))\n",
        "plt.imshow(image_np_with_detections)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbAjnEdBassJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}